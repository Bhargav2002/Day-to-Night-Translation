# Day-to-Night-Translation
This project employs Cycle Generative Adversarial Networks (GANs) to transform high-resolution day cityscape images into night images and vice versa. The dataset comprises high-resolution images captured during both day and night. The unique aspect of Cycle GANs is their ability to utilize the dataset without explicit image-target pairs. Instead, they incorporate cycle consistency loss to maintain the semantic and structural components of the images. Essentially, Cycle GANs extend Pix2Pix GANs by introducing an additional Cycle Consistency loss, ensuring the preservation of meaningful features in the generated images.
## Formulation:
Our goal is to learn two mapping functions G,F over two domains X,Y ; such that G: X -> Y and F : Y -> X. We can think of X as set of pictures, and Y as the set of paintings, for the task of converting Pictures to Paintings. The functions G and F are Generators. 

We also have adverserial discriminators Dx and Dy, where Dx has the task to discriminating between images from set X (pictures) and set of images generated by F(Y)/X_hat (i.e the image generated by the inverse mapping Generator F). Similarly Dy has the task to discriminating between images from set Y (Paintings) and set of images generated by G(X)/Y_hat  (i.e the image generated by the generator G) .

We guide the training of the GAN using an objective that has two components : 
1) Adverserial loss: For mapping of input domain to target domain, and vice versa.
2) Cycle Consistency loss:  For enforcing cycle consistency so that F(G(X)) = X and G(F(Y)) = Y

## Implementation:
1) Architecture : Used the generator architecture from Johnson et al, with instance normalization. The discriminator uses a PatchGAN, which classifies wheather 70*70 patch in the image is real or fake.
2) Training Detail: 
   a) Adverserial Loss : Replace the Log-likelyhood adverserial loss with the Least Square loss, as it is more stable during training.
   b) Total loss : Used the cycle consistency loss weighting parameter Lambda  = 10 .
   c) Optimization : Used Adam optimizer with LR = 0.0002 for first 100 epoch, linealy decaying into 0 in next 100 epochs. (i.e total 200 epochs)
   d) Batch Size : 1 
   c) Training updates: Used history of training images for updating Dx and Dy, using a buffer that stores 50 previously generated images . This reduces model oscillations (from strivastava et al).
